{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c0353300-e262-44a6-ab51-279244a71277",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Delta Lake Overview\n",
    "\n",
    "---\n",
    "\n",
    "## üìå What is Delta Lake?\n",
    "\n",
    "- **Open-source storage framework** designed to improve data lake reliability.\n",
    "- Solves issues like **data inconsistency** and **performance bottlenecks**.\n",
    "- Acts as a **storage layer** enabling a **lakehouse architecture** (combining data warehousing + analytics).\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Delta Lake: What It Is and Isn‚Äôt\n",
    "\n",
    "**Delta Lake IS:**\n",
    "- Open-source technology\n",
    "- Storage framework/layer\n",
    "- Enables building a lakehouse\n",
    "\n",
    "**Delta Lake IS NOT:**\n",
    "- Proprietary technology\n",
    "- A storage format/medium\n",
    "- A data warehouse or database service\n",
    "\n",
    "---\n",
    "\n",
    "## üîë Key Components of Delta Lake\n",
    "\n",
    "### Tables:\n",
    "- Stored in **Parquet** format.\n",
    "\n",
    "### Transaction Log (Delta Log):\n",
    "- Records every transaction (insert, update, delete).\n",
    "- Acts as a **single source of truth**.\n",
    "- Stored as **JSON files**, capturing operation history.\n",
    "- Spark uses the Delta Log to read the latest data version.\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Delta Lake Operations\n",
    "\n",
    "### Creating & Reading Tables:\n",
    "1. **Writer process:** Creates Delta table, writes data files.\n",
    "2. Updates the **Delta Log**.\n",
    "3. **Reader process:** Checks Delta Log to load correct data files.\n",
    "\n",
    "### Updating Records:\n",
    "- Updates create **new files**, keeping old versions intact.\n",
    "- Transaction log records the update, ensuring only latest version is read.\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ Handling Concurrent Operations\n",
    "\n",
    "- **Readers & Writers can run simultaneously.**\n",
    "- Delta Lake avoids deadlocks and conflicts by isolating write operations.\n",
    "- Readers always see consistent, up-to-date data.\n",
    "\n",
    "---\n",
    "\n",
    "## üö´ Error Handling\n",
    "\n",
    "- Failed write operations **do NOT update** the Delta Log.\n",
    "- Prevents access to incomplete or corrupt data.\n",
    "- Ensures readers only access valid, clean data.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚≠ê Advantages of Delta Lake\n",
    "\n",
    "- **ACID Transactions:** Reliable transactions on large-scale data lakes.\n",
    "- **Scalable Metadata Management:** Handles millions of files efficiently.\n",
    "- **Comprehensive Audit Trail:** Tracks all changes for traceability.\n",
    "\n",
    "---\n",
    "\n",
    "## üìÇ File Formats Used\n",
    "\n",
    "- **Parquet:** For storing table data.\n",
    "- **JSON:** For transaction logs (Delta Log).\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ Conclusion\n",
    "\n",
    "Delta Lake enhances the reliability, consistency, and performance of data lakes by providing:\n",
    "- ACID compliance\n",
    "- Auditability\n",
    "- Support for concurrent workloads\n",
    "\n",
    "The next step is practicing these features in Databricks notebooks.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1 - Delta Lake Notes",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
